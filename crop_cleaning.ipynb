{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helper import unzip_gz, zip_gz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/qs.crops_20240926.txt.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/qs.crops_20240926.txt.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(f, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(filename, gz_mode, compresslevel)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, mode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/qs.crops_20240926.txt.gz'"
     ]
    }
   ],
   "source": [
    "with gzip.open('data/qs.crops_20240926.txt.gz', 'rt') as f:\n",
    "    df = pd.read_csv(f, delimiter='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['COUNTRY_NAME', 'COUNTRY_CODE', 'STATE_NAME', 'STATE_ALPHA',\n",
    "                      'STATE_FIPS_CODE', 'STATE_ANSI', 'COUNTY_ANSI', 'COUNTY_CODE',\n",
    "                      'REGION_DESC', 'ZIP_5', 'WATERSHED_DESC', 'CONGR_DISTRICT_CODE',\n",
    "                      'LOAD_TIME', 'CV_%', 'BEGIN_CODE', 'END_CODE', 'WATERSHED_CODE',\n",
    "                      'ASD_CODE', 'SOURCE_DESC', 'SECTOR_DESC', 'GROUP_DESC',\n",
    "                      'UTIL_PRACTICE_DESC', 'WEEK_ENDING', 'COUNTY_NAME', 'ASD_DESC'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = [\"WHEAT\", \"CORN\", \"HAY\", \"SOYBEANS\", \"BARLEY\", \"OATS\", \"SORGHUM\", \"COTTON\",\n",
    "         \"BEANS\", \"POTATOES\", \"TOBACCO\", \"PEANUTS\", \"SUNFLOWER\", \"APPLES\", \"RYE\",\n",
    "         \"RICE\", \"PEACHES\", \"TOMATOES\", \"SWEET CORN\", \"PEAS\", \"PEARS\", \"SUGARBEETS\",\n",
    "         \"MELONS\", \"PECANS\", \"BLUEBERRIES\", \"SQUASH\", \"ONIONS\", \"LETTUCE\", \"PEPPERS\",\n",
    "         \"GRAPES\", \"SWEET POTATOES\", \"CHERRIES\", \"STRAWBERRIES\", \"CABBAGE\", \"CUCUMBERS\",\n",
    "         \"ORANGES\", \"RASPBERRIES\", \"PUMPKINS\", \"BLACKBERRIES\", \"PLUMS & PRUNES\", \"CARROTS\",\n",
    "         \"BROCCOLI\", \"SUGARCANE\", \"GARLIC\", \"ASPARAGUS\", \"SPINACH\", \"BEETS\", \"GRAPEFRUIT\",\n",
    "         \"EGGPLANT\", \"APRICOTS\", \"CAULIFLOWER\", \"LEMONS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['COMMODITY_DESC'].isin(crops)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the df to only the 52 crops in the crops list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_units = ['OPERATIONS', 'PCT FAIR', 'PCT VERY POOR', '$ / BU', '$',\n",
    "             '$ / TON', '$ / CWT', 'ACRES', 'PCT POOR', '$ / BOX, PHD EQUIV',\n",
    "             'PCT', '$ / BOX, ON TREE EQUIV', 'NUMBER', 'SQ FT', 'CENTS / BU',\n",
    "             'PCT OF PARITY', 'INDEX', '$, PHD EQUIV', '$ / BOX, FOB',\n",
    "             'PCT BY SIZE GROUP', 'PCT BY GRADE', 'PCT NONE', 'PCT LIGHT',\n",
    "             'PCT MODERATE', 'POINTS / LB', 'PCT OF FARM SALES',\n",
    "             'PCT OF TOTAL STOCKS', 'CUERDAS', 'PCT ACTIVE', 'PCT OF FARM OPERATIONS',\n",
    "             '$ / BOX', '$ / TON, DRY BASIS' ,'REACTIONS SINCE 1984', 'PCT OF PRODUCTION',\n",
    "             'PCT OF MKTG YEAR', '$ / LB', ]\n",
    "\n",
    "for item, value in filtered_df['UNIT_DESC'].value_counts().items():\n",
    "    if value <= 500:\n",
    "        not_units.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df.loc[~filtered_df['UNIT_DESC'].isin(not_units)]\n",
    "\n",
    "for key, value in df['UNIT_DESC'].value_counts().items():\n",
    "    print(key,  value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if all 50 states are in the LOCATION_DESC column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\",\n",
    "    \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\",\n",
    "    \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\",\n",
    "    \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\",\n",
    "    \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\",\n",
    "    \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "zip_df = pd.read_csv(\"data/uszips.csv\")\n",
    "zip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df = zip_df[zip_df['state_name'].isin(all_states)]\n",
    "zip_df = zip_df[['zip', 'state_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df['zip'] = zip_df['zip'].astype(str)\n",
    "\n",
    "zip_to_state = dict(zip(zip_df['zip'], zip_df['state_name']))\n",
    "\n",
    "capitalized_states = [item.upper() for item in all_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_region_with_state(location):\n",
    "    \"\"\"Function that checks if state name is in LOCATION_DESC if the name contains a state name but is not just\n",
    "    the state name it converts it into only the state name. For example OREGON SOUTHWEST DOUGLAS becomes OREGON\"\"\"\n",
    "    for state in capitalized_states:\n",
    "        if state in location:\n",
    "            return state\n",
    "\n",
    "    if location in zip_to_state:\n",
    "        print(f\"Zip:{location} State:{zip_to_state[location].upper()}\")\n",
    "        return zip_to_state[location].upper()\n",
    "\n",
    "    print(f\"NONE {location}\")\n",
    "    return \"NONE\"\n",
    "\n",
    "df['LOCATION_DESC'] = df['LOCATION_DESC'].apply(replace_region_with_state)\n",
    "df['LOCATION_DESC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list = []\n",
    "\n",
    "for key in df['LOCATION_DESC'].value_counts().keys():\n",
    "    location_list.append(key)\n",
    "len(location_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in df['LOCATION_DESC'].value_counts().keys():\n",
    "    print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['LOCATION_DESC'] != \"NONE\"]\n",
    "df['LOCATION_DESC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 7,131,741  Column:14\n"
     ]
    }
   ],
   "source": [
    "row, column = df.shape\n",
    "print(f\"Row: {row:,}  Column:{column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['YEAR'] >= 1980) & (df['YEAR'] <= 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_info_crops = []\n",
    "for crop, amount in df['COMMODITY_DESC'].value_counts().items():\n",
    "    if amount <= 1500:\n",
    "        no_info_crops.append(crop)\n",
    "\n",
    "df = df.loc[~df['COMMODITY_DESC'].isin(no_info_crops)]\n",
    "df['COMMODITY_DESC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['CLASS_DESC', 'CLASS_DESC', 'STATISTICCAT_DESC', 'SHORT_DESC',\n",
    "                      'DOMAIN_DESC', 'DOMAINCAT_DESC', 'AGG_LEVEL_DESC', 'FREQ_DESC',\n",
    "                      'REFERENCE_PERIOD_DESC', 'PRODN_PRACTICE_DESC'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2731136 entries, 16 to 22309639\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   COMMODITY_DESC  object \n",
      " 1   UNIT_DESC       object \n",
      " 2   LOCATION_DESC   object \n",
      " 3   YEAR            int64  \n",
      " 4   VALUE           float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 125.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df['VALUE'] = pd.to_numeric(df['VALUE'], errors='coerce')\n",
    "df = df.dropna(subset=['VALUE'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masongalusha/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Apply log transformation to 'VALUE'\n",
    "# Use np.log1p to handle zero values safely\n",
    "df['log_value'] = np.log1p(df['VALUE'])\n",
    "\n",
    "# Compute group-wise lower and upper percentiles on log-transformed data\n",
    "# Here, we're using the 5th and 95th percentiles\n",
    "df['lower_percentile'] = df.groupby(['COMMODITY_DESC', 'UNIT_DESC'])['log_value'].transform(lambda x: x.quantile(0.05))\n",
    "df['upper_percentile'] = df.groupby(['COMMODITY_DESC', 'UNIT_DESC'])['log_value'].transform(lambda x: x.quantile(0.95))\n",
    "\n",
    "# Clip log-transformed values to the percentile range\n",
    "df['clipped_log_value'] = df['log_value'].clip(lower=df['lower_percentile'], upper=df['upper_percentile'])\n",
    "\n",
    "# Apply the normalization formula\n",
    "df['normalized_value'] = (\n",
    "    (df['clipped_log_value'] - df['lower_percentile']) /\n",
    "    (df['upper_percentile'] - df['lower_percentile'])\n",
    ") * 100\n",
    "\n",
    "# Handle division by zero when lower_percentile == upper_percentile\n",
    "equal_percentile_mask = df['upper_percentile'] == df['lower_percentile']\n",
    "df.loc[equal_percentile_mask, 'normalized_value'] = df.loc[equal_percentile_mask, 'VALUE'].apply(lambda x: 100 if x != 0 else 0)\n",
    "\n",
    "# Clip normalized values to be between 0 and 100\n",
    "df['normalized_value'] = df['normalized_value'].clip(lower=0, upper=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,731,136\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMODITY_DESC</th>\n",
       "      <th>UNIT_DESC</th>\n",
       "      <th>LOCATION_DESC</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>normalized_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOYBEANS</td>\n",
       "      <td>BU / ACRE</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>2014</td>\n",
       "      <td>92.499630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HAY</td>\n",
       "      <td>TONS / ACRE</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>2001</td>\n",
       "      <td>50.044943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUGARBEETS</td>\n",
       "      <td>PCT GOOD</td>\n",
       "      <td>IDAHO</td>\n",
       "      <td>2022</td>\n",
       "      <td>55.783833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>COTTON</td>\n",
       "      <td>PCT EXCELLENT</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2010</td>\n",
       "      <td>37.311430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>HAY</td>\n",
       "      <td>TONS / ACRE</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>1989</td>\n",
       "      <td>33.524074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COMMODITY_DESC      UNIT_DESC LOCATION_DESC  YEAR  normalized_value\n",
       "16       SOYBEANS      BU / ACRE       INDIANA  2014         92.499630\n",
       "35            HAY    TONS / ACRE        KANSAS  2001         50.044943\n",
       "36     SUGARBEETS       PCT GOOD         IDAHO  2022         55.783833\n",
       "45         COTTON  PCT EXCELLENT    CALIFORNIA  2010         37.311430\n",
       "48            HAY    TONS / ACRE     MINNESOTA  1989         33.524074"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['log_value', 'lower_percentile', 'upper_percentile', 'clipped_log_value', 'VALUE'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_gz(df, \"data/clean_crop.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
